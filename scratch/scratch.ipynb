{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad0562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import plotly.express as px\n",
    "\n",
    "with open(\"../queries/count_score.sql\") as query_file:\n",
    "    query = query_file.read()\n",
    "    with duckdb.connect(\"../data/anime_data.duckdb\") as conn:\n",
    "        df = conn.execute(query).fetchdf()\n",
    "        print(df)\n",
    "        print(df[\"count\"].sum())\n",
    "        fig = px.bar(df, x=\"score\", y=\"count\", title=\"Score Count\")\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17888d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import plotly.express as px\n",
    "\n",
    "with open(\"../queries/count_score_by_top_genre.sql\") as query_file:\n",
    "    query = query_file.read()\n",
    "    with duckdb.connect(\"../data/anime_data.duckdb\") as conn:\n",
    "        df = conn.execute(query).fetchdf()\n",
    "        print(df)\n",
    "        fig = px.bar(df, x=\"score\", y=\"count\", color=\"genre\", title=\"Score Count by Top Genre\")\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c949c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import plotly.express as px\n",
    "\n",
    "with open(\"../queries/count_score_by_top_tag.sql\") as query_file:\n",
    "    query = query_file.read()\n",
    "    with duckdb.connect(\"../data/anime_data.duckdb\") as conn:\n",
    "        df = conn.execute(query).fetchdf()\n",
    "        print(df)\n",
    "        fig = px.bar(df, x=\"score\", y=\"count\", color=\"tag\", title=\"Score Count by Top Tag\")\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f11cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "with duckdb.connect(\"../data/anime_data.duckdb\") as conn:\n",
    "    conn.sql(\"COPY (FROM dbt.anime_scores) TO '../data/anime_scores.parquet' (FORMAT parquet)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839026d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession as session\n",
    "from pyspark.sql.functions import count_distinct, desc\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "spark = session.builder.appName(\"Anime Data Pipeline - Spark\").config(\"spark.memory.offHeap.enabled\", \"true\").config(\"spark.memory.offHeap.size\", \"2g\").getOrCreate()\n",
    "\n",
    "df = spark.read.parquet(\"../data/anime_scores.parquet\")\n",
    "aggs = df.groupBy(\"score\").agg(count_distinct(\"media_id\").alias(\"count\")).filter(df[\"score\"] > 0.0).orderBy(desc(\"count\"), desc(\"score\"))\n",
    "aggs.show()\n",
    "\n",
    "table = df.createOrReplaceTempView(\"anime_scores\")\n",
    "query = \"\"\"SELECT\n",
    "  score,\n",
    "  COUNT(DISTINCT(media_id)) AS count\n",
    "FROM\n",
    "  anime_scores\n",
    "WHERE\n",
    "  score > 0.0\n",
    "GROUP BY\n",
    "  score\n",
    "ORDER BY\n",
    "  count DESC, score DESC\"\"\"\n",
    "result = spark.sql(query)\n",
    "result.show()\n",
    "\n",
    "with_tags = df.select(\"media_id\", \"score\", \"tag\").filter(df[\"tag\"].isNotNull())\n",
    "with_genres = df.select(\"media_id\", \"score\", \"genre\").filter(df[\"genre\"].isNotNull())\n",
    "joined = with_tags.join(with_genres, [\"media_id\", \"score\"]).distinct()\n",
    "joined.show()\n",
    "\n",
    "indexer = StringIndexer(inputCols=[\"tag\", \"genre\"], outputCols=[\"tag_indexed\", \"genre_indexed\"])\n",
    "indexed_df = indexer.fit(joined).transform(joined)\n",
    "indexed_df.show()\n",
    "\n",
    "encoder_tag = OneHotEncoder(inputCols=[\"tag_indexed\"], outputCols=[\"tag_one_hot\"])\n",
    "encoded_tag_df = encoder_tag.fit(indexed_df).transform(indexed_df)\n",
    "assembler_tag = VectorAssembler(inputCols=[\"score\", \"tag_one_hot\"], outputCol=\"features\")\n",
    "assembled_tag_df = assembler_tag.transform(encoded_tag_df)\n",
    "scaler_tag = StandardScaler(inputCol=\"features\", outputCol=\"standardized_tag\")\n",
    "scaled_tag_df = scaler_tag.fit(assembled_tag_df).transform(assembled_tag_df)\n",
    "scaled_tag_df.select(\"standardized_tag\").show(truncate=False)\n",
    "\n",
    "encoder_genre = OneHotEncoder(inputCols=[\"genre_indexed\"], outputCols=[\"genre_one_hot\"])\n",
    "encoded_genre_df = encoder_genre.fit(indexed_df).transform(indexed_df)\n",
    "assembler_genre = VectorAssembler(inputCols=[\"score\", \"genre_one_hot\"], outputCol=\"features\")\n",
    "assembled_genre_df = assembler_genre.transform(encoded_genre_df)\n",
    "scaler_genre = StandardScaler(inputCol=\"features\", outputCol=\"standardized\")\n",
    "scaled_genre_df = scaler_genre.fit(assembled_genre_df).transform(assembled_genre_df)\n",
    "scaled_genre_df.select(\"standardized\").show(truncate=False)\n",
    "\n",
    "max_clusters = 100\n",
    "cost = np.zeros(max_clusters)\n",
    "evaluator = ClusteringEvaluator(predictionCol=\"prediction\", featuresCol=\"standardized\", metricName=\"silhouette\", distanceMeasure=\"squaredEuclidean\")\n",
    "for i in range(2, max_clusters):\n",
    "    KMeans_algo = KMeans(featuresCol=\"standardized\", k=i)\n",
    "    KMeans_fit = KMeans_algo.fit(scaled_genre_df)\n",
    "    output = KMeans_fit.transform(scaled_genre_df)\n",
    "    cost[i] = KMeans_fit.summary.trainingCost\n",
    "\n",
    "cost_df = pd.DataFrame(cost[2:])\n",
    "cost_df.columns = [\"cost\"]\n",
    "new_col = range(2, max_clusters)\n",
    "cost_df.insert(0, \"cluster\", new_col)\n",
    "fig = px.line(cost_df, x=\"cluster\", y=\"cost\", title=\"Cluster vs Cost\")\n",
    "fig.show()\n",
    "KMeans_algo = KMeans(featuresCol='standardized', k=18)\n",
    "predictions = KMeans_algo.fit(scaled_genre_df).transform(scaled_genre_df)\n",
    "predictions.show()\n",
    "\n",
    "viz_df = predictions.select(\"score\", \"genre\", \"prediction\")\n",
    "viz_df = viz_df.toPandas()\n",
    "list1 = [\"score\", \"genre\"]\n",
    "for i in list1:\n",
    "    sns.barplot(x=\"prediction\", y=str(i), data=viz_df)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa515fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "\n",
    "from kafka import KafkaProducer, KafkaConsumer\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "USER_NAME = os.getenv(\"USER_NAME\")\n",
    "KAFKA_URL = os.getenv(\"KAFKA_URL\")\n",
    "RAW_MEDIA_LIST_TOPIC = os.getenv(\"RAW_MEDIA_LIST_TOPIC\")\n",
    "RAW_USER_TOPIC = os.getenv(\"RAW_USER_TOPIC\")\n",
    "FACT_ANIME_TOPIC = os.getenv(\"FACT_ANIME_TOPIC\")\n",
    "DIMENSION_MEDIA_TOPIC = os.getenv(\"DIMENSION_MEDIA_TOPIC\")\n",
    "DIMENSION_USER_TOPIC = os.getenv(\"DIMENSION_USER_TOPIC\")\n",
    "ANILIST_QUERY = \"../queries/anilist.graphql\"\n",
    "KAFKA_API_VERSION = (4, 0, 0)\n",
    "\n",
    "def produce():\n",
    "    query_path = ANILIST_QUERY\n",
    "    with open(query_path, \"r\") as query_file:\n",
    "        print(\"querying AniList\")\n",
    "        query = query_file.read()\n",
    "        body = {\n",
    "            \"query\": query,\n",
    "            \"variables\": {\n",
    "                \"userName\": USER_NAME,\n",
    "            },\n",
    "        }\n",
    "        res = requests.post(\"https://graphql.anilist.co\", json=body)\n",
    "        data = res.json()\n",
    "\n",
    "        producer = KafkaProducer(\n",
    "            bootstrap_servers=[KAFKA_URL],\n",
    "            value_serializer=lambda v: json.dumps(v).encode(\"utf-8\"),\n",
    "            api_version=KAFKA_API_VERSION,\n",
    "        )\n",
    "        count = 0\n",
    "\n",
    "        print(\"sending raw user\")\n",
    "        user = data[\"data\"][\"User\"]\n",
    "        producer.send(RAW_USER_TOPIC, user)\n",
    "        count += 1\n",
    "\n",
    "        print(\"sending raw entries\")\n",
    "        for lst in data[\"data\"][\"MediaListCollection\"][\"lists\"]:\n",
    "            for entry in lst[\"entries\"]:\n",
    "                producer.send(RAW_MEDIA_LIST_TOPIC, entry)\n",
    "                count += 1\n",
    "\n",
    "        print(f\"sent {count} messages\")\n",
    "        print(\"flushing\")\n",
    "        producer.flush()\n",
    "        producer.close()\n",
    "\n",
    "def consume():\n",
    "    consumer = KafkaConsumer(\n",
    "        bootstrap_servers=[KAFKA_URL],\n",
    "        value_deserializer=json.loads,\n",
    "        api_version=KAFKA_API_VERSION,\n",
    "        consumer_timeout_ms=5000,\n",
    "        auto_offset_reset=\"earliest\",\n",
    "        group_id=None\n",
    "    )\n",
    "\n",
    "    consumer.subscribe(\n",
    "        topics=[\n",
    "            RAW_MEDIA_LIST_TOPIC,\n",
    "            RAW_USER_TOPIC,\n",
    "            FACT_ANIME_TOPIC,\n",
    "            DIMENSION_MEDIA_TOPIC,\n",
    "            DIMENSION_USER_TOPIC,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    while not consumer.poll():\n",
    "        print(\"waiting for messages\")\n",
    "        time.sleep(1)\n",
    "        continue\n",
    "\n",
    "    print(\"seeking to beginning\")\n",
    "    consumer.seek_to_beginning()\n",
    "\n",
    "    print(\"processing messages\")\n",
    "    count = 0\n",
    "    for msg in consumer:\n",
    "        print(msg.value)\n",
    "        count += 1\n",
    "\n",
    "    print(f\"processed {count} messages\")\n",
    "    print(\"closing\")\n",
    "    consumer.close()\n",
    "\n",
    "produce()\n",
    "consume()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
